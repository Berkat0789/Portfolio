{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data = pd.DataFrame(load_breast_cancer()[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data[\"target\"] = load_breast_cancer()[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1       2       3        4        5        6        7       8  \\\n",
       "0    17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710  0.2419   \n",
       "1    20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690  0.07017  0.1812   \n",
       "2    19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740  0.12790  0.2069   \n",
       "3    11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520  0.2597   \n",
       "4    20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430  0.1809   \n",
       "..     ...    ...     ...     ...      ...      ...      ...      ...     ...   \n",
       "564  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390  0.13890  0.1726   \n",
       "565  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400  0.09791  0.1752   \n",
       "566  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251  0.05302  0.1590   \n",
       "567  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140  0.15200  0.2397   \n",
       "568   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000  0.00000  0.1587   \n",
       "\n",
       "           9  ...     21      22      23       24       25      26      27  \\\n",
       "0    0.07871  ...  17.33  184.60  2019.0  0.16220  0.66560  0.7119  0.2654   \n",
       "1    0.05667  ...  23.41  158.80  1956.0  0.12380  0.18660  0.2416  0.1860   \n",
       "2    0.05999  ...  25.53  152.50  1709.0  0.14440  0.42450  0.4504  0.2430   \n",
       "3    0.09744  ...  26.50   98.87   567.7  0.20980  0.86630  0.6869  0.2575   \n",
       "4    0.05883  ...  16.67  152.20  1575.0  0.13740  0.20500  0.4000  0.1625   \n",
       "..       ...  ...    ...     ...     ...      ...      ...     ...     ...   \n",
       "564  0.05623  ...  26.40  166.10  2027.0  0.14100  0.21130  0.4107  0.2216   \n",
       "565  0.05533  ...  38.25  155.00  1731.0  0.11660  0.19220  0.3215  0.1628   \n",
       "566  0.05648  ...  34.12  126.70  1124.0  0.11390  0.30940  0.3403  0.1418   \n",
       "567  0.07016  ...  39.42  184.60  1821.0  0.16500  0.86810  0.9387  0.2650   \n",
       "568  0.05884  ...  30.37   59.16   268.6  0.08996  0.06444  0.0000  0.0000   \n",
       "\n",
       "         28       29  target  \n",
       "0    0.4601  0.11890       0  \n",
       "1    0.2750  0.08902       0  \n",
       "2    0.3613  0.08758       0  \n",
       "3    0.6638  0.17300       0  \n",
       "4    0.2364  0.07678       0  \n",
       "..      ...      ...     ...  \n",
       "564  0.2060  0.07115       0  \n",
       "565  0.2572  0.06637       0  \n",
       "566  0.2218  0.07820       0  \n",
       "567  0.4087  0.12400       0  \n",
       "568  0.2871  0.07039       1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cancer_data.drop(\"target\", axis = 1).values\n",
    "y = cancer_data[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scalar.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_Stop = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=3, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/berkatbhatti/Desktop/python/Portfolio/Deep Learning and Neural Networks'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will set the the log events for tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## if we are running this model with different parameters and want a different directory for the logs add  time stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-04-22--1355'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().strftime(\"%Y-%m-%d-%--%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit\"\n",
    "board = TensorBoard( log_dir=log_dir,\n",
    "    histogram_freq=1,\n",
    "    write_graph=True,\n",
    "    write_images=False,\n",
    "    update_freq='epoch',\n",
    "    profile_batch=2,\n",
    "    embeddings_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 30)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units = 30, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units = 10, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units = 15, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units = 15, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "model.compile(optimization = \"adam\", loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 398 samples, validate on 171 samples\n",
      "Epoch 1/300\n",
      "398/398 [==============================] - 3s 7ms/sample - loss: 0.7118 - val_loss: 0.6886\n",
      "Epoch 2/300\n",
      "398/398 [==============================] - 0s 411us/sample - loss: 0.7012 - val_loss: 0.6855\n",
      "Epoch 3/300\n",
      "398/398 [==============================] - 0s 415us/sample - loss: 0.6856 - val_loss: 0.6810\n",
      "Epoch 4/300\n",
      "398/398 [==============================] - 0s 415us/sample - loss: 0.6905 - val_loss: 0.6788\n",
      "Epoch 5/300\n",
      "398/398 [==============================] - 0s 420us/sample - loss: 0.6828 - val_loss: 0.6752\n",
      "Epoch 6/300\n",
      "398/398 [==============================] - 0s 414us/sample - loss: 0.6704 - val_loss: 0.6710\n",
      "Epoch 7/300\n",
      "398/398 [==============================] - 0s 415us/sample - loss: 0.6630 - val_loss: 0.6631\n",
      "Epoch 8/300\n",
      "398/398 [==============================] - 0s 417us/sample - loss: 0.6717 - val_loss: 0.6621\n",
      "Epoch 9/300\n",
      "398/398 [==============================] - 0s 421us/sample - loss: 0.6568 - val_loss: 0.6523\n",
      "Epoch 10/300\n",
      "398/398 [==============================] - 0s 419us/sample - loss: 0.6538 - val_loss: 0.6448\n",
      "Epoch 11/300\n",
      "398/398 [==============================] - 0s 417us/sample - loss: 0.6553 - val_loss: 0.6389\n",
      "Epoch 12/300\n",
      "398/398 [==============================] - 0s 421us/sample - loss: 0.6413 - val_loss: 0.6291\n",
      "Epoch 13/300\n",
      "398/398 [==============================] - 0s 417us/sample - loss: 0.6391 - val_loss: 0.6217\n",
      "Epoch 14/300\n",
      "398/398 [==============================] - 0s 417us/sample - loss: 0.6253 - val_loss: 0.6147\n",
      "Epoch 15/300\n",
      "398/398 [==============================] - 0s 418us/sample - loss: 0.6165 - val_loss: 0.6045\n",
      "Epoch 16/300\n",
      "398/398 [==============================] - 0s 423us/sample - loss: 0.6116 - val_loss: 0.5979\n",
      "Epoch 17/300\n",
      "398/398 [==============================] - 0s 418us/sample - loss: 0.6058 - val_loss: 0.5879\n",
      "Epoch 18/300\n",
      "398/398 [==============================] - 0s 420us/sample - loss: 0.6076 - val_loss: 0.5749\n",
      "Epoch 19/300\n",
      "398/398 [==============================] - 0s 416us/sample - loss: 0.5902 - val_loss: 0.5649\n",
      "Epoch 20/300\n",
      "398/398 [==============================] - 0s 416us/sample - loss: 0.5759 - val_loss: 0.5513\n",
      "Epoch 21/300\n",
      "398/398 [==============================] - 0s 419us/sample - loss: 0.5639 - val_loss: 0.5358\n",
      "Epoch 22/300\n",
      "398/398 [==============================] - 0s 417us/sample - loss: 0.5667 - val_loss: 0.5259\n",
      "Epoch 23/300\n",
      "398/398 [==============================] - 0s 416us/sample - loss: 0.5477 - val_loss: 0.5079\n",
      "Epoch 24/300\n",
      "398/398 [==============================] - 0s 419us/sample - loss: 0.5389 - val_loss: 0.4916\n",
      "Epoch 25/300\n",
      "398/398 [==============================] - 0s 417us/sample - loss: 0.5254 - val_loss: 0.4794\n",
      "Epoch 26/300\n",
      "398/398 [==============================] - 0s 417us/sample - loss: 0.5422 - val_loss: 0.4773\n",
      "Epoch 27/300\n",
      "398/398 [==============================] - 0s 421us/sample - loss: 0.5168 - val_loss: 0.4645\n",
      "Epoch 28/300\n",
      "398/398 [==============================] - 0s 418us/sample - loss: 0.5242 - val_loss: 0.4534\n",
      "Epoch 29/300\n",
      "398/398 [==============================] - 0s 418us/sample - loss: 0.5219 - val_loss: 0.4435\n",
      "Epoch 30/300\n",
      "398/398 [==============================] - 0s 420us/sample - loss: 0.4887 - val_loss: 0.4232\n",
      "Epoch 31/300\n",
      "398/398 [==============================] - 0s 415us/sample - loss: 0.4925 - val_loss: 0.4167\n",
      "Epoch 32/300\n",
      "398/398 [==============================] - 0s 415us/sample - loss: 0.4855 - val_loss: 0.4048\n",
      "Epoch 33/300\n",
      "398/398 [==============================] - 0s 442us/sample - loss: 0.4986 - val_loss: 0.4008\n",
      "Epoch 34/300\n",
      "398/398 [==============================] - 0s 416us/sample - loss: 0.4410 - val_loss: 0.3845\n",
      "Epoch 35/300\n",
      "398/398 [==============================] - 0s 416us/sample - loss: 0.4733 - val_loss: 0.3943\n",
      "Epoch 36/300\n",
      "398/398 [==============================] - 0s 426us/sample - loss: 0.4533 - val_loss: 0.3798\n",
      "Epoch 37/300\n",
      "398/398 [==============================] - 0s 454us/sample - loss: 0.4660 - val_loss: 0.3678\n",
      "Epoch 38/300\n",
      "398/398 [==============================] - 0s 420us/sample - loss: 0.4403 - val_loss: 0.3624\n",
      "Epoch 39/300\n",
      "398/398 [==============================] - 0s 423us/sample - loss: 0.4042 - val_loss: 0.3492\n",
      "Epoch 40/300\n",
      "398/398 [==============================] - 0s 423us/sample - loss: 0.4160 - val_loss: 0.3455\n",
      "Epoch 41/300\n",
      "398/398 [==============================] - 0s 435us/sample - loss: 0.4161 - val_loss: 0.3419\n",
      "Epoch 42/300\n",
      "398/398 [==============================] - 0s 436us/sample - loss: 0.4126 - val_loss: 0.3323\n",
      "Epoch 43/300\n",
      "398/398 [==============================] - 0s 459us/sample - loss: 0.3766 - val_loss: 0.3268\n",
      "Epoch 44/300\n",
      "398/398 [==============================] - 0s 424us/sample - loss: 0.4160 - val_loss: 0.3238\n",
      "Epoch 45/300\n",
      "398/398 [==============================] - 0s 435us/sample - loss: 0.3940 - val_loss: 0.3221\n",
      "Epoch 46/300\n",
      "398/398 [==============================] - 0s 423us/sample - loss: 0.3637 - val_loss: 0.3241\n",
      "Epoch 47/300\n",
      "398/398 [==============================] - 0s 435us/sample - loss: 0.3742 - val_loss: 0.3183\n",
      "Epoch 48/300\n",
      "398/398 [==============================] - 0s 435us/sample - loss: 0.3984 - val_loss: 0.3103\n",
      "Epoch 49/300\n",
      "398/398 [==============================] - 0s 415us/sample - loss: 0.3461 - val_loss: 0.2950\n",
      "Epoch 50/300\n",
      "398/398 [==============================] - 0s 418us/sample - loss: 0.3495 - val_loss: 0.2885\n",
      "Epoch 51/300\n",
      "398/398 [==============================] - 0s 420us/sample - loss: 0.4032 - val_loss: 0.3050\n",
      "Epoch 52/300\n",
      "398/398 [==============================] - 0s 416us/sample - loss: 0.3280 - val_loss: 0.2935\n",
      "Epoch 53/300\n",
      "398/398 [==============================] - 0s 432us/sample - loss: 0.3833 - val_loss: 0.2901\n",
      "Epoch 54/300\n",
      "398/398 [==============================] - 0s 437us/sample - loss: 0.3460 - val_loss: 0.2797\n",
      "Epoch 55/300\n",
      "398/398 [==============================] - 0s 442us/sample - loss: 0.3360 - val_loss: 0.2757\n",
      "Epoch 56/300\n",
      "398/398 [==============================] - 0s 429us/sample - loss: 0.3546 - val_loss: 0.2783\n",
      "Epoch 57/300\n",
      "398/398 [==============================] - 0s 414us/sample - loss: 0.3356 - val_loss: 0.2771\n",
      "Epoch 58/300\n",
      "398/398 [==============================] - 0s 419us/sample - loss: 0.3409 - val_loss: 0.2875\n",
      "Epoch 59/300\n",
      "398/398 [==============================] - 0s 429us/sample - loss: 0.3410 - val_loss: 0.3004\n",
      "Epoch 60/300\n",
      "398/398 [==============================] - 0s 420us/sample - loss: 0.3515 - val_loss: 0.2788\n",
      "Epoch 61/300\n",
      "398/398 [==============================] - 0s 416us/sample - loss: 0.3290 - val_loss: 0.2785\n",
      "Epoch 62/300\n",
      "398/398 [==============================] - 0s 414us/sample - loss: 0.3384 - val_loss: 0.2711\n",
      "Epoch 63/300\n",
      "398/398 [==============================] - 0s 420us/sample - loss: 0.2965 - val_loss: 0.2645\n",
      "Epoch 64/300\n",
      "398/398 [==============================] - 0s 423us/sample - loss: 0.2916 - val_loss: 0.2632\n",
      "Epoch 65/300\n",
      "398/398 [==============================] - 0s 413us/sample - loss: 0.3287 - val_loss: 0.2552\n",
      "Epoch 66/300\n",
      "398/398 [==============================] - 0s 412us/sample - loss: 0.2934 - val_loss: 0.2577\n",
      "Epoch 67/300\n",
      "398/398 [==============================] - 0s 410us/sample - loss: 0.2915 - val_loss: 0.2578\n",
      "Epoch 68/300\n",
      "398/398 [==============================] - 0s 418us/sample - loss: 0.3023 - val_loss: 0.2563\n",
      "Epoch 69/300\n",
      "398/398 [==============================] - 0s 414us/sample - loss: 0.3385 - val_loss: 0.2479\n",
      "Epoch 70/300\n",
      "398/398 [==============================] - 0s 415us/sample - loss: 0.2736 - val_loss: 0.2494\n",
      "Epoch 71/300\n",
      "398/398 [==============================] - 0s 417us/sample - loss: 0.2707 - val_loss: 0.2486\n",
      "Epoch 72/300\n",
      "398/398 [==============================] - 0s 419us/sample - loss: 0.3065 - val_loss: 0.2484\n",
      "Epoch 73/300\n",
      "398/398 [==============================] - 0s 416us/sample - loss: 0.2766 - val_loss: 0.2478\n",
      "Epoch 74/300\n",
      "398/398 [==============================] - 0s 417us/sample - loss: 0.2877 - val_loss: 0.2407\n",
      "Epoch 75/300\n",
      "398/398 [==============================] - 0s 412us/sample - loss: 0.2929 - val_loss: 0.2512\n",
      "Epoch 76/300\n",
      "398/398 [==============================] - 0s 415us/sample - loss: 0.2614 - val_loss: 0.2491\n",
      "Epoch 77/300\n",
      "398/398 [==============================] - 0s 415us/sample - loss: 0.2571 - val_loss: 0.2508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/300\n",
      "398/398 [==============================] - 0s 417us/sample - loss: 0.2665 - val_loss: 0.2486\n",
      "Epoch 79/300\n",
      "398/398 [==============================] - 0s 409us/sample - loss: 0.2488 - val_loss: 0.2468\n",
      "Epoch 80/300\n",
      "398/398 [==============================] - 0s 413us/sample - loss: 0.2401 - val_loss: 0.2421\n",
      "Epoch 81/300\n",
      "398/398 [==============================] - 0s 413us/sample - loss: 0.2666 - val_loss: 0.2457\n",
      "Epoch 82/300\n",
      "398/398 [==============================] - 0s 412us/sample - loss: 0.2535 - val_loss: 0.2440\n",
      "Epoch 83/300\n",
      "398/398 [==============================] - 0s 415us/sample - loss: 0.2173 - val_loss: 0.2555\n",
      "Epoch 84/300\n",
      "398/398 [==============================] - 0s 415us/sample - loss: 0.2462 - val_loss: 0.2468\n",
      "Epoch 85/300\n",
      "398/398 [==============================] - 0s 413us/sample - loss: 0.2434 - val_loss: 0.2421\n",
      "Epoch 86/300\n",
      "398/398 [==============================] - 0s 414us/sample - loss: 0.2370 - val_loss: 0.2459\n",
      "Epoch 87/300\n",
      "398/398 [==============================] - 0s 412us/sample - loss: 0.2721 - val_loss: 0.2498\n",
      "Epoch 88/300\n",
      "398/398 [==============================] - 0s 414us/sample - loss: 0.2436 - val_loss: 0.2434\n",
      "Epoch 89/300\n",
      "398/398 [==============================] - 0s 413us/sample - loss: 0.2653 - val_loss: 0.2365\n",
      "Epoch 90/300\n",
      "398/398 [==============================] - 0s 411us/sample - loss: 0.2686 - val_loss: 0.2301\n",
      "Epoch 91/300\n",
      "398/398 [==============================] - 0s 412us/sample - loss: 0.2262 - val_loss: 0.2209\n",
      "Epoch 92/300\n",
      "398/398 [==============================] - 0s 414us/sample - loss: 0.2738 - val_loss: 0.2353\n",
      "Epoch 93/300\n",
      "398/398 [==============================] - 0s 413us/sample - loss: 0.2230 - val_loss: 0.2251\n",
      "Epoch 94/300\n",
      "398/398 [==============================] - 0s 413us/sample - loss: 0.2169 - val_loss: 0.2282\n",
      "Epoch 95/300\n",
      "398/398 [==============================] - 0s 411us/sample - loss: 0.2136 - val_loss: 0.2300\n",
      "Epoch 96/300\n",
      "398/398 [==============================] - 0s 414us/sample - loss: 0.1877 - val_loss: 0.2488\n",
      "Epoch 97/300\n",
      "398/398 [==============================] - 0s 408us/sample - loss: 0.2614 - val_loss: 0.2426\n",
      "Epoch 98/300\n",
      "398/398 [==============================] - 0s 413us/sample - loss: 0.2136 - val_loss: 0.2487\n",
      "Epoch 99/300\n",
      "398/398 [==============================] - 0s 411us/sample - loss: 0.2003 - val_loss: 0.2490\n",
      "Epoch 100/300\n",
      "398/398 [==============================] - 0s 412us/sample - loss: 0.2681 - val_loss: 0.2332\n",
      "Epoch 101/300\n",
      "398/398 [==============================] - 0s 415us/sample - loss: 0.2632 - val_loss: 0.2316\n",
      "Epoch 102/300\n",
      "398/398 [==============================] - 0s 411us/sample - loss: 0.2008 - val_loss: 0.2288\n",
      "Epoch 103/300\n",
      "398/398 [==============================] - 0s 410us/sample - loss: 0.1942 - val_loss: 0.2332\n",
      "Epoch 104/300\n",
      "398/398 [==============================] - 0s 412us/sample - loss: 0.2085 - val_loss: 0.2266\n",
      "Epoch 105/300\n",
      "398/398 [==============================] - 0s 415us/sample - loss: 0.2128 - val_loss: 0.2344\n",
      "Epoch 106/300\n",
      "398/398 [==============================] - 0s 411us/sample - loss: 0.2444 - val_loss: 0.2434\n",
      "Epoch 107/300\n",
      "398/398 [==============================] - 0s 414us/sample - loss: 0.1996 - val_loss: 0.2437\n",
      "Epoch 108/300\n",
      "398/398 [==============================] - 0s 424us/sample - loss: 0.2081 - val_loss: 0.2437\n",
      "Epoch 109/300\n",
      "398/398 [==============================] - 0s 413us/sample - loss: 0.1967 - val_loss: 0.2404\n",
      "Epoch 110/300\n",
      "398/398 [==============================] - 0s 413us/sample - loss: 0.1918 - val_loss: 0.2398\n",
      "Epoch 111/300\n",
      "398/398 [==============================] - 0s 412us/sample - loss: 0.1929 - val_loss: 0.2412\n",
      "Epoch 112/300\n",
      "398/398 [==============================] - 0s 413us/sample - loss: 0.2162 - val_loss: 0.2377\n",
      "Epoch 113/300\n",
      "398/398 [==============================] - 0s 414us/sample - loss: 0.2192 - val_loss: 0.2500\n",
      "Epoch 114/300\n",
      "398/398 [==============================] - 0s 416us/sample - loss: 0.2014 - val_loss: 0.2515\n",
      "Epoch 115/300\n",
      "398/398 [==============================] - 0s 425us/sample - loss: 0.1767 - val_loss: 0.2685\n",
      "Epoch 116/300\n",
      "398/398 [==============================] - 0s 418us/sample - loss: 0.1799 - val_loss: 0.2633\n",
      "Epoch 00116: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a501cea90>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=300, callbacks=[early_Stop,board])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performnce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a50cedd50>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(model.history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model has a 96% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95        66\n",
      "           1       0.96      0.97      0.97       105\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.96      0.96      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 62   4]\n",
      " [  3 102]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lets pass in random new features to check if the model will predict accurately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       21.610000\n",
       "1       22.280000\n",
       "2      144.400000\n",
       "3     1407.000000\n",
       "4        0.116700\n",
       "5        0.208700\n",
       "6        0.281000\n",
       "7        0.156200\n",
       "8        0.216200\n",
       "9        0.066060\n",
       "10       0.624200\n",
       "11       0.920900\n",
       "12       4.158000\n",
       "13      80.990000\n",
       "14       0.005215\n",
       "15       0.037260\n",
       "16       0.047180\n",
       "17       0.012880\n",
       "18       0.020450\n",
       "19       0.004028\n",
       "20      26.230000\n",
       "21      28.740000\n",
       "22     172.000000\n",
       "23    2081.000000\n",
       "24       0.150200\n",
       "25       0.571700\n",
       "26       0.705300\n",
       "27       0.242200\n",
       "28       0.382800\n",
       "29       0.100700\n",
       "Name: 393, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randint\n",
    "random_index = randint(0,len(cancer_data))\n",
    "\n",
    "new_feature = cancer_data.drop(\"target\", axis =1).iloc[random_index]\n",
    "new_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = scalar.transform(new_feature.values.reshape(1,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0]], dtype=int32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WE can inspect this by passing in the random index in to the dataFrame. We can see that our model predicted correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data.iloc[random_index][\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/berkatbhatti/Desktop/python/Portfolio/Deep Learning and Neural Networks'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
