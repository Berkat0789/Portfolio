{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Overview:\n",
    "- For this project you will need to fetch Adj Close every company in the Russell 2000 for 2020 (Time Frame Jan 1 - current) \n",
    "- We would like to see the Dips and Gains/ Daily Returns of every stock under priced under 10 dollars in ascending order.\n",
    "- Repeat the same process for every company in the entire index\n",
    "- Using portfolio optimization techniques find 20 companies in a portfolio that would generate a \"Good\" return during the current Pandemic. \n",
    "- We want you to than go back 5 years and see how these companies performed pre-Covid. What is the max return we would have received during this 5 year period considering volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Approach\n",
    "- Fetch all companies in Russell 2000\n",
    "- Use pandas Datareader to get the Adj Close\n",
    "- Calculate the Daily returns for each security\n",
    "- Find the top 20 Gains and Dips for returns for the current day\n",
    "- Put every security into a portfolio and optimize the portfolio with 5 years of data (2015-2019 end)\n",
    "- Find the top companies the make up the index by weight and isolate them into a portfolio of their own\n",
    "- Run a portfolio optimization on the portfolio using Markowitz Efficient Frontier and see what the ortfolio would have returned pre-Covid. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgements\n",
    "- Data was downloaded provided from Ben Reynolds at Secure Dividends\n",
    "- https://www.suredividend.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from pandas_datareader import data as web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "russ = pd.read_excel(\"resources/Russle_2000_2020.xlsx\", index_col='Ticker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Overview \n",
    "- Data below provides all of the data tickers and companies in the Russell 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAN</th>\n",
       "      <td>Aaron's, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAOI</th>\n",
       "      <td>Applied Optoelectronics, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAON</th>\n",
       "      <td>AAON, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAT</th>\n",
       "      <td>American Assets Trust, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAWW</th>\n",
       "      <td>Atlas Air Worldwide Holdings, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIXI</th>\n",
       "      <td>Zix Corp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZUMZ</th>\n",
       "      <td>Zumiez, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZUO</th>\n",
       "      <td>Zuora, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZYNE</th>\n",
       "      <td>Zynerba Pharmaceuticals, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZYXI</th>\n",
       "      <td>Zynex, Inc.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1999 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Name\n",
       "Ticker                                    \n",
       "AAN                          Aaron's, Inc.\n",
       "AAOI         Applied Optoelectronics, Inc.\n",
       "AAON                            AAON, Inc.\n",
       "AAT            American Assets Trust, Inc.\n",
       "AAWW    Atlas Air Worldwide Holdings, Inc.\n",
       "...                                    ...\n",
       "ZIXI                             Zix Corp.\n",
       "ZUMZ                          Zumiez, Inc.\n",
       "ZUO                            Zuora, Inc.\n",
       "ZYNE         Zynerba Pharmaceuticals, Inc.\n",
       "ZYXI                           Zynex, Inc.\n",
       "\n",
       "[1999 rows x 1 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "russ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1999 entries, AAN to ZYXI\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Name    1999 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 31.2+ KB\n"
     ]
    }
   ],
   "source": [
    "russ.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adj Closes\n",
    "- Will import data already fetched previously\n",
    "- Will download the Adj Close for each security for 2020 beginning 2020-1-1 to current using pandas Datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = list(russ.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#failed = []\n",
    "#passed = []\n",
    "#for x in tickers:\n",
    "   # try:\n",
    "      #  data[x] = web.DataReader(x, data_source= \"yahoo\", start = \"2020-6-1\")[\"Adj Close\"]\n",
    "      #  passed.append(x)\n",
    "   # except (IOError, KeyError):\n",
    "        #msg = 'Failed to read symbol: {0!r}, replacing with NaN.'\n",
    "       # failed.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passed Tickers\n",
    "- There are 1941 tickers that passed in the Yahoo data reader library\n",
    "- We will use these for our analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Passed Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "penny = pd.read_csv(\"resources/current/penny_tickers.csv\", index_col= \"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>under 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACRS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACRX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>YCBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>YRCW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>ZIOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>ZIXI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>ZYNE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>346 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    under 10\n",
       "0       ABEO\n",
       "1       ACER\n",
       "2       ACOR\n",
       "3       ACRS\n",
       "4       ACRX\n",
       "..       ...\n",
       "341     YCBD\n",
       "342     YRCW\n",
       "343     ZIOP\n",
       "344     ZIXI\n",
       "345     ZYNE\n",
       "\n",
       "[346 rows x 1 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "penny_tickers = list(penny[\"under 10\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "penny_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = []\n",
    "passed = []\n",
    "for x in list(penny_tickers):\n",
    "    try:\n",
    "        penny_data[x] = web.DataReader(x, data_source= \"yahoo\", start = \"2020-8-10\")[\"Adj Close\"]\n",
    "        passed.append(x)\n",
    "    except (IOError, KeyError):\n",
    "        msg = 'Failed to read symbol: {0!r}, replacing with NaN.'\n",
    "        failed.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 5 entries, 2020-08-10 to 2020-08-14\n",
      "Columns: 340 entries, ABEO to ZYNE\n",
      "dtypes: float64(340)\n",
      "memory usage: 13.3 KB\n"
     ]
    }
   ],
   "source": [
    "penny_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(penny_tickers, columns=[\"under 10\"]).to_csv(\"resources/current/penny_tickers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the Daily returns for  the Russell 2000\n",
    "- Will check today's Date for the Dips and Spikes in the entire index\n",
    "- Will find the to 20 companies that had a negative return for todays date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "todays_Date = penny_data.iloc[-1:].iloc[0].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOOK HERE FOR Gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = penny_data.iloc[-1:].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_gains= penny_data.pct_change().iloc[-1:].transpose().sort_values(todays_Date, ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "gains_andPrice = pd.concat([sorted_gains, prices], axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "gains_andPrice.columns = [\"gains\", \"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gains</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OCN</th>\n",
       "      <td>13.879433</td>\n",
       "      <td>20.9800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IPI</th>\n",
       "      <td>9.730666</td>\n",
       "      <td>12.8768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRTY</th>\n",
       "      <td>0.275862</td>\n",
       "      <td>2.5900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XERS</th>\n",
       "      <td>0.136240</td>\n",
       "      <td>4.1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LXU</th>\n",
       "      <td>0.131443</td>\n",
       "      <td>2.1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDSI</th>\n",
       "      <td>0.126652</td>\n",
       "      <td>5.1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRK</th>\n",
       "      <td>0.105482</td>\n",
       "      <td>6.6550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MR</th>\n",
       "      <td>0.101490</td>\n",
       "      <td>5.9150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNCR</th>\n",
       "      <td>0.092417</td>\n",
       "      <td>4.6100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.090361</td>\n",
       "      <td>1.8100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          gains    price\n",
       "OCN   13.879433  20.9800\n",
       "IPI    9.730666  12.8768\n",
       "PRTY   0.275862   2.5900\n",
       "XERS   0.136240   4.1700\n",
       "LXU    0.131443   2.1950\n",
       "BDSI   0.126652   5.1150\n",
       "CRK    0.105482   6.6550\n",
       "MR     0.101490   5.9150\n",
       "SNCR   0.092417   4.6100\n",
       "SD     0.090361   1.8100"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gains_andPrice.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dips "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_dips = data.pct_change()[-1:].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_dips.plot(kind = \"bar\", figsize = (16,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_Spikes = data.pct_change()[-1:].transpose().sort_values(\"2020-07-13\", ascending = False).dropna().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_Spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_Spikes.plot(kind = \"bar\", figsize = (16,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing the Russell 2000 as a portfolio\n",
    "- Will put every company in a portfolio and see which companies would have held the mose weight during the 2020 covid 19 crisis thu far. \n",
    "- Will use markowitz Portfolio theor to optimize the Russell\n",
    "- Will use 2000 randomly allocated portfolios to get the efficient frontier using a combination of volatility and expected returns\n",
    "- We will drop companies with missing data for the time being"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "russell_Returns = data.dropna(axis=1).pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = list(russell_Returns.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_portfolios = 2000\n",
    "all_weights = np.zeros((n_portfolios, len(tic)))\n",
    "all_returns = np.zeros(n_portfolios)\n",
    "all_vol = np.zeros(n_portfolios)\n",
    "all_sharp = np.zeros(n_portfolios)\n",
    "\n",
    "for ind in range(n_portfolios):\n",
    "    weights = np.array(np.random.random(len(tic)))\n",
    "    weights = weights/weights.sum()   \n",
    "    all_weights[ind,:] = weights\n",
    "    \n",
    "    all_returns[ind] = np.sum(russell_Returns.mean() * weights) * 252\n",
    "    all_vol[ind] = np.dot(weights.T, np.dot(russell_Returns.cov() * 252, weights))\n",
    "    all_sharp[ind] = all_returns[ind]/ all_vol[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Frontier\n",
    "- The frontier will provide a good insight on the max return hightest sharp and the lowest volatility of the portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hightest_return = all_returns.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_vol = all_vol.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "higherst_sharp = all_sharp.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_returns.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frontier \n",
    "- We see two things in the froniter\n",
    "- The portfolio with the highest sharp is provides the same return as the portfolio with the highrest return \n",
    "- Appears the highest return for a portfolio containing every company in the Russell is in the negative\n",
    "- This is not realistic and the main purpose was to find the top 20 weighted companies in 2020\n",
    "- We will fetch these below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,10))\n",
    "plt.scatter(all_vol, all_returns, c=all_sharp)\n",
    "plt.scatter(all_vol[hightest_return], all_returns[hightest_return], c=\"r\", s = 160)\n",
    "plt.scatter(all_vol[lowest_vol], all_returns[lowest_vol], c=\"orange\", s = 80)\n",
    "plt.scatter(all_vol[higherst_sharp], all_returns[higherst_sharp], c=\"black\", s = 60)\n",
    "\n",
    "plt.colorbar(label = \"Sharp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bringing the data together \n",
    "- Creating a data frame for the weights returns and sharp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontier_df = pd.DataFrame(all_returns, columns=[\"returns\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontier_df = pd.concat([frontier_df, pd.DataFrame(all_vol, columns=[\"vol\"])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_df = pd.DataFrame(all_sharp, columns=[\"shp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontier_df = pd.concat([frontier_df, shp_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_df = pd.DataFrame(all_weights, columns=tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontier_df = pd.concat([frontier_df, weights_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## frontier_df.to_csv(\"resources/current/frontier_entier_russell.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets find the portfolio with the highest returns\n",
    "- Will take the top 20 compaines by weight in this portfolio and create a new portfolio with just these 20 companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_ret_port = pd.DataFrame(frontier_df.sort_values(\"returns\", ascending = False).loc[1869])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_ret_port.drop([\"returns\", \"vol\", \"shp\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below are the top 20 weighted companies \n",
    "- will create a portfolio for just these companies and see what our returns would have been for 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_weighted = highest_ret_port.sort_values(1869, ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top20_tickers = list(top_20_weighted.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in top20_tickers:\n",
    "    top_20_df[y] = web.DataReader(y, data_source=\"yahoo\", start = \"2020-1-1\")[\"Adj Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_df.plot(figsize = (16,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_returns = top_20_df.pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility \n",
    "- This portfolio has a high vol minly occurring with 2 companies\n",
    "- Lets calculate the volatility below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(top_20_returns.mean() * 252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_returns.plot(figsize = (16,6), legend = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_portfolios = 2000\n",
    "all_weights = np.zeros((n_portfolios, len(top_20_df.columns)))\n",
    "all_returns = np.zeros(n_portfolios)\n",
    "all_vol = np.zeros(n_portfolios)\n",
    "all_sharp = np.zeros(n_portfolios)\n",
    "\n",
    "for ind in range(n_portfolios):\n",
    "    weights = np.array(np.random.random(len(top_20_df.columns)))\n",
    "    weights = weights/weights.sum()   \n",
    "    all_weights[ind,:] = weights\n",
    "    \n",
    "    all_returns[ind] = np.sum(top_20_returns.mean() * weights) * 252\n",
    "    all_vol[ind] = np.dot(weights.T, np.dot(top_20_returns.cov() * 252, weights))\n",
    "    all_sharp[ind] = all_returns[ind]/ all_vol[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_return = all_returns.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_Sharp = all_sharp.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_vol = all_vol.argmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "- This portfolio would have yielded you 38% return year to date \n",
    "- Not bad even during Covid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_returns.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sharp.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vol.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.scatter(all_vol, all_returns, c=all_sharp)\n",
    "plt.scatter(all_vol[max_return], all_returns[max_return], c=\"r\", s = 80)\n",
    "plt.scatter(all_vol[max_Sharp], all_returns[max_Sharp], c=\"black\", s = 40)\n",
    "plt.scatter(all_vol[lowest_vol], all_returns[lowest_vol], c=\"r\", s = 40)\n",
    "plt.colorbar(label = \"Sharp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
